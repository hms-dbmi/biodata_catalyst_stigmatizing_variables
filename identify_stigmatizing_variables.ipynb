{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65dca1e2",
   "metadata": {},
   "source": [
    "# BioData Catalyst Powered by PIC-SURE: Identify stigmatizing variables\n",
    "\n",
    "The purpose of this notebook is to identify stigmatizing variables in [BioData Catalyst Powered by PIC-SURE](https://picsure.biodatacatalyst.nhlbi.nih.gov/). Specifically, stigmatizing variables will be identified in PIC-SURE Authorized Access and removed for PIC-SURE Open Access.\n",
    "\n",
    "For more information about stigmatizing variables, please view the [README.md](https://github.com/hms-dbmi/biodata_catalyst_stigmatizing_variables#biodata_catalyst_stigmatizing_variables).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ca3a7",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "This notebook assumes knowledge of the BioData Catalyst Powered by PIC-SURE platform, data structure, and API. For more information about the API, please visit the [Access to Data using PIC-SURE GitHub repository](https://github.com/hms-dbmi/Access-to-Data-using-PIC-SURE-API).\n",
    "\n",
    "Developer login credentials or access to all data in PIC-SURE Authorized Access is also required to ensure all variables are reviewed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d31d37",
   "metadata": {},
   "source": [
    "### Connect to PIC-SURE\n",
    "\n",
    "Be sure to save your user-specific token as `token.txt` prior to running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45182406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-client.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git@new-search\n",
    "\n",
    "import PicSureBdcAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment production URL below for production environment\n",
    "# PICSURE_network_URL = \"https://picsure.biodatacatalyst.nhlbi.nih.gov/picsure\"\n",
    "PICSURE_network_URL = \"https://biodatacatalyst.integration.hms.harvard.edu/picsure\"\n",
    "token_file = \"token.txt\"\n",
    "\n",
    "with open(token_file, \"r\") as f:\n",
    "    my_token = f.read()\n",
    "    \n",
    "bdc = PicSureBdcAdapter.Adapter(PICSURE_network_URL, my_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca910c16",
   "metadata": {},
   "source": [
    "\n",
    "### Save all variables of interest in PIC-SURE Authorized Access to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ac3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = bdc.useDictionary().dictionary() # Set up the dictionary\n",
    "all_vars = dictionary.find(\"phs002415\") # Fill in with phs number of interest, phs002415\n",
    "all_variables = all_vars.dataframe() # Retrieve all variables you have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578589db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c26a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = all_variables[[\"columnmeta_HPDS_PATH\", \"varId\", \"columnmeta_name\", \"columnmeta_description\", \n",
    "                          \"columnmeta_var_group_description\", \"columnmeta_var_id\", \"values\",\n",
    "                         \"columnmeta_var_group_id\", \"dtId\"]]\n",
    "clean_df.head()\n",
    "#clean_df = all_variables[[\"HPDS_PATH\", \"variable\", \"name\", \"description\", \n",
    "#                          \"var_report_description\", \"var_name\", \"var_report_comment\", \"values\",\n",
    "#                         \"dataTableName\", \"dataTableDescription\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to make a single string of information from the strings provided\n",
    "\n",
    "def is_same(term1, term2):\n",
    "    if term1 == term2:\n",
    "        return term1\n",
    "    elif term1 == \"\":\n",
    "        return term2\n",
    "    elif term2 == \"\":\n",
    "        return term1\n",
    "    else:\n",
    "        final = str(term1)+\" <<AND>> \"+str(term2)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following code used to consolidate the multiple columns of information and prep dataframe for \n",
    "# stigmatizing variable identification\n",
    "\n",
    "final_var_info = []\n",
    "final_dt_info = []\n",
    "for i, path in enumerate(clean_df.columnmeta_HPDS_PATH):\n",
    "    cur_var_info = []\n",
    "    variable = clean_df.varId[i]\n",
    "    if variable != '':\n",
    "        cur_var_info.append(variable)\n",
    "    name = is_same(clean_df.columnmeta_name[i], clean_df.columnmeta_description[i])\n",
    "    if name != '':\n",
    "        cur_var_info.append(name)\n",
    "    if len(cur_var_info) == 0:\n",
    "        cur_var_info = \"<<NO INFO AVAILABLE>>\"\n",
    "    final_var_info.append(cur_var_info)\n",
    "    #clean_df.curated_var_info[i] = cur_var_info\n",
    "    \n",
    "    cur_dt_info = []\n",
    "    dt_name = clean_df.columnmeta_var_group_id[i]\n",
    "    if dt_name != '':\n",
    "        cur_dt_info.append(dt_name)\n",
    "    dt_desc = clean_df.columnmeta_var_group_description[i]\n",
    "    if dt_desc != '':\n",
    "        cur_dt_info.append(dt_desc)\n",
    "    if len(cur_dt_info) == 0:\n",
    "        cur_dt_info = \"<<NO INFO AVAILABLE>>\"\n",
    "    final_dt_info.append(cur_dt_info)\n",
    "clean_df['curated_var_info'] = final_var_info\n",
    "clean_df['curated_dt_info'] = final_dt_info\n",
    "df = clean_df[['columnmeta_HPDS_PATH', 'curated_var_info', 'curated_dt_info', 'values']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f5834",
   "metadata": {},
   "source": [
    "### Define functions and load information for stigmatizing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of stigmatizing terms, inclusion terms, and exclusion terms\n",
    "stigmatizing_df = pd.read_csv(\"stigmatizing_terms/stigmatizing_keywords.tsv\", sep=\"\\t\")\n",
    "terms_included_df = pd.read_csv(\"stigmatizing_terms/inclusion_terms.tsv\", sep='\\t')\n",
    "terms_excluded_df = pd.read_csv(\"stigmatizing_terms/revamped_exclusion.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52829df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses the stigmatizing keywords to flag a term as needing review\n",
    "import re\n",
    "def check_vars(varlist, df, exclude_vars=[]):\n",
    "    stig_var_list = []\n",
    "    #excluded_var_list = []\n",
    "    for i in range(0, len(df[\"curated_var_info\"])):\n",
    "        mini = \"N\"\n",
    "        for var in varlist:\n",
    "            if mini == \"N\":\n",
    "                if re.search(var, str(df['curated_var_info'][i]), re.IGNORECASE):\n",
    "                #for ex in exclude_vars:\n",
    "                #    if df['simplified_name'][i].lower() == ex:\n",
    "                #        if df['simplified_name'][i] not in excluded_var_list:\n",
    "                #            excluded_var_list.append(df['name'][i])\n",
    "                #if df['name'][i] not in excluded_var_list:\n",
    "                    #stig_var_list.append(\"Y\")\n",
    "                    mini = \"Y\"\n",
    "            else:\n",
    "                break\n",
    "        stig_var_list.append(mini)\n",
    "    df[\"need_review\"] = stig_var_list\n",
    "    return df[df.need_review == \"Y\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f7c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses the inclusion terms to automatically flag as stigmatizing\n",
    "def automatic_inclusion(df, inclusion_terms):\n",
    "    df[\"stigmatizing\"] = \"NA\"\n",
    "    for i in range(0, len(df.columnmeta_HPDS_PATH)):\n",
    "        mini = \"N\"\n",
    "        for var in inclusion_terms:\n",
    "            if mini == \"N\":\n",
    "                if re.search(var, str(df['curated_var_info'][i]), re.IGNORECASE):\n",
    "                    mini = \"Y\"\n",
    "                    df[\"stigmatizing\"][i] = \"Y\"\n",
    "            else:\n",
    "                break\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses the exclusion terms to automatically flag as not stigmatizing\n",
    "def exclude_terms(df, var_list):\n",
    "    for i in range(0, len(df.columnmeta_HPDS_PATH)):\n",
    "        if df.stigmatizing[i] == \"NA\":\n",
    "            mini = \"NA\"\n",
    "            for var in var_list:\n",
    "                if mini == \"NA\":\n",
    "                    if re.search(var, str(df['curated_var_info'][i]), re.IGNORECASE):\n",
    "                        mini = \"N\"\n",
    "                        df['stigmatizing'][i] = \"N\"\n",
    "                else:\n",
    "                    break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to interactively review the remaining variables and save decisions\n",
    "from ast import literal_eval\n",
    "def decide(df):\n",
    "    stig_vars = []\n",
    "    non_stig_vars = []\n",
    "    for i in range(0, len(df.HPDS_PATH)):\n",
    "        print(i)\n",
    "        test = df.curated_var_info[i].replace(\" nan]\", \" 'nan']\")\n",
    "        var_info = literal_eval(test)\n",
    "        if df.stigmatizing[i] == \"Y\" and var_info[1].lower() not in stig_vars:\n",
    "            newstring = ''.join([j for j in var_info[1].lower() if not j.isdigit()])\n",
    "            stig_vars.append(newstring.lower())\n",
    "            print(\"Adding\", newstring, \"to stig vars\")\n",
    "            #continue\n",
    "        if df.stigmatizing[i] == \"N\" and var_info[1].lower() not in non_stig_vars:\n",
    "            newstring = ''.join([j for j in var_info[1].lower() if not j.isdigit()])\n",
    "            non_stig_vars.append(newstring.lower())\n",
    "            print(\"Adding\", newstring, \"to non stig vars\")\n",
    "            #continue\n",
    "        #if df.stigmatizing[i] == \"NA\":\n",
    "        else:\n",
    "            newstring = ''.join([j for j in var_info[1].lower() if not j.isdigit()])\n",
    "            if newstring in stig_vars:\n",
    "                result = \"Y\"\n",
    "                print(\"Recording result \", i, \"of\", len(df.HPDS_PATH))\n",
    "                df.stigmatizing[i] = result\n",
    "                continue\n",
    "            elif newstring in non_stig_vars:\n",
    "                result = \"N\"\n",
    "                print(\"Recording result\", i, \"of\", len(df.HPDS_PATH))\n",
    "                df.stigmatizing[i] = result\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Variable\", i, \"of\", len(df.HPDS_PATH))\n",
    "                print(var_info)\n",
    "                result = input(\"Stigmatizing? Y/N/more: \")\n",
    "                if result == \"more\":\n",
    "                    print(df.curated_dt_info[i])\n",
    "                    result = input(\"Table info. Stigmatizing? Y/N: \")\n",
    "                if result == \"pause\":\n",
    "                    print(\"Pausing stigmatizing variable identification\")\n",
    "                    return(df)\n",
    "                if result == \"Y\":\n",
    "                    #newstring = ''.join([j for j in var_info[1].lower() if not j.isdigit()])\n",
    "                    stig_vars.append(newstring.lower())\n",
    "                if result == \"N\":\n",
    "                    #newstring = ''.join([j for j in var_info[1].lower() if not j.isdigit()])\n",
    "                    non_stig_vars.append(newstring.lower())\n",
    "                df.stigmatizing[i] = result\n",
    "            #return(stig_vars)\n",
    "        #else:\n",
    "        #    continue\n",
    "    print(\"Stigmatizing variables complete.\")\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7981a2",
   "metadata": {},
   "source": [
    "### Run the functions and make stigmatizing decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad50cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = check_vars(stigmatizing_df['Search keyword'], df)\n",
    "test2 = automatic_inclusion(test, terms_included_df[\"Terms to include\"])\n",
    "test2.head()\n",
    "df_inc_exc = exclude_terms(test2, terms_excluded_df[\"TERMS TO EXCLUDE\"])\n",
    "df_inc_exc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and adjust code below if you paused the stigmatizing variable identification process and \n",
    "# need to load other results\n",
    "\n",
    "#final_output = 'stigmatizing_variable_results/REVAMP_stigmatizing_variables_decisions.txt'\n",
    "#df_inc_exc = pd.read_csv(final_output, sep='\\t')\n",
    "#df_inc_exc.fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dcbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = decide(df_inc_exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = 'stigmatizing_variable_results/REVAMP_stigmatizing_variables_decisions.txt'\n",
    "df_final.to_csv(final_output, sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6976c",
   "metadata": {},
   "source": [
    "## Export stig vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724770a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(final_output, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442fce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a7a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to stig vars\n",
    "stigvars = df[df.stigmatizing == \"Y\"].columnmeta_HPDS_PATH.reset_index(drop=True)\n",
    "stigvars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"stigmatizing_variable_results/REVAMP_stigmatizing_variables.txt\"\n",
    "df_final.to_csv(out, sep='\\t', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
